---
title: 指令系统
date: 2025-06-22 16:48:45
categories:
    - 408
    - 计算机组成原理
---

## 指令寻址和数据寻址
指令寻址都是根据PC获取，顺序寻址时下一个地址就是PC+1(1条指令的长度)，跳跃寻址由本条指令给出PC的计算方式

### 数据寻址
指令包括操作码，寻址特征和形式地址A
- 隐含寻址，没给出操作数的地址，如累加器ACC，操作数由其内部提供
- 立即寻址，指令字中的地址字段指出的不是操作数的地址，而是操作数本身，也称立即数，采用补码表示
- 直接寻址，形式地址A 就是操作数的直实地址EA
- 间接寻址，指令的地址字段给出的不是操作数的真正地址，而是操作数有效地址所在主存单元的地址，也就是操作数地址的地址
- 寄存器寻址，与直接寻址的原理一样， 只是把访问主存改为访问寄存器(寄存器在CPU内部，访问速度最快)， 指令的地址字段给出的是操作数所在寄存器的编号
- 寄存器间接寻址，指令字中的地址所指向的寄存器给出的不是一个操作数， 而是操作数所在主存单元的地址
- 相对寻址，相对寻址是把PC的内容加上指令格式中的形式地址A而形成操作数的有效地址， 即EA =(PC) +A,其中A是相对于当前PC值的偏移量， 可正可负，补码表示。这么做的优点是相对地址是程序内部的相对地址，如程序存储到1000，A=10，那么数据就存储到1010，这样程序就可以任意浮动，不会因为改变到其他地址就找不到数据了
- 基址寻址，基址寻址是指将基址寄存器(BR) 的内容加上指令字中的形式地址A而形成操作数的有效地址，即EA=(BR)+A。其中基址寄存器既可采用专用寄存器，又可指定某个通用寄存器作为基址寄存器，优点是寄存器可以拓展A的位数，进而扩大寻址范围， 在动态重定位中，程序被加载到内存的哪个位置是不确定的。 基址寻址允许程序在加载时，只需设置基址寄存器为程序的起始地址，程序内部的所有内存访问指令 (使用基址寻址的) 就能自动适应新的加载位置，实现代码的浮动。 现代操作系统中，进程通常拥有独立的数据段。  基址寄存器可以指向进程的数据段起始地址，方便程序访问其数据段内的变量和数据结构。 例如，C 语言中的全局变量和静态变量通常就存放在数据段中，可以使用基址寻址来访问。
- 变址寻址，变址寄存器的值加上指令中给出的偏移量，它与上一个的区别是变址寻址的核心目的是**方便对数组、字符串等连续存储的数据结构进行访问**。**变址寄存器通常用于存放索引值或下标值。** 指令中的偏移量则表示数组或字符串的首地址（基地址），或者数组元素的固定偏移量。而变址寄存器在循环中频繁改变。基址寻址中基址寄存器的值指向程序首地址后不会轻易改变

## 程序的机器级代码表示
![](https://res.cloudinary.com/dkdhhe5fc/image/upload/v1750585543/36lj13_c504tu.png)

- \<reg\>: regsiter 寄存器，reg32表示32位寄存器
- \<mem\>: memory 内存
- \<con\>: constant 常数，\<con8\>表示8位常数
指令：
- mov，可以复制第二个操作数到第一个，允许reg<-reg，reg<-mem，mem<-reg，reg<-con，mem<-con，不允许mem<-mem。指令mov byte ptr [var], 5 表示mov是移动指令；byte是大小指示符，表示要操作的数据大小；ptr是指针指示符，表示**紧跟在 `ptr` 后面的操作数是一个内存地址 (指针)**，而不是立即数或寄存器名。[var]是内存寻址，5是要复制的操作数。所以整体意思就是把5复制到var指示的内存地址的一字节中

## 多处理器 并行处理

| 特性 | SISD (单指令单数据) | SIMD (单指令多数据) | MIMD (多指令多数据) |
| :--- | :--- | :--- | :--- |
| **指令流** | 1 | 1 | N (多个) |
| **数据流** | 1 | N (多个) | N (多个) |
| **并行类型** | 无 (或指令级并行) | **数据并行** | **任务并行** |
| **执行方式** | 串行 | 同步并行 | **异步并行** |
| **架构复杂度**| 简单 | 中等 | 复杂 |
| **应用场景** | 传统串行任务 | 图形、科学计算、AI | 通用并行计算、服务器 |
| **典型代表** | 老式单核CPU | GPU, 向量处理器 | **现代多核CPU**, 服务器集群 |

如GPU的核心就是大规模的SIMD架构，它拥有数千个核心，可以同时对图像中的成千上万个像素点执行相同的变换操作。

### 硬件多线程
核心思想是让单个物理核心能够维护多个硬件线程的完整状态（如程序计数器、寄存器组），并在纳秒级别上进行切换。当一个硬件线程因为某些原因（如缓存未命中、等待内存）发生停顿时，核心可以立刻切换到另一个硬件线程去执行，从而提高单个物理核心的利用率，Intel的商业名称叫超线程。在单核处理器上也能使用

### 共享内存多处理器
1.  **UMA (Uniform Memory Access) - 均匀存储访问模型**
    * **核心特征**：所有处理器访问任何内存位置的**时间都相同**。物理内存被所有处理器集中共享。
    * **典型实现**：**对称多处理器 (Symmetric Multiprocessing, SMP)**。在SMP中，所有CPU地位平等，共享所有资源，并运行同一个操作系统内核。这是目前PC和服务器中最常见的模型。
    * **优点**：编程模型简单，负载均衡易于实现。
    * **缺点**：所有处理器共享同一总线和内存，当处理器数量增多时，总线和内存会成为性能瓶颈，**可伸缩性（Scalability）较差**。

2.  **NUMA (Non-Uniform Memory Access) - 非均匀存储访问模型**
    * **核心特征**：处理器访问不同内存区域的**时间不同**。内存被物理上划分为多个模块，每个模块与一组处理器“本地连接”。
    * **工作机制**：访问“本地内存”速度快，访问连接到其他处理器的“远程内存”速度慢。
    * **优点**：通过减少对单一共享总线的争用，**大大提高了可伸缩性**，能够支持更多数量的处理器。
    * **缺点**：编程模型更复杂，需要操作系统和程序员有意识地将进程及其数据放置在本地内存中以获得最佳性能。
